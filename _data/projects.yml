- repo: elliptic-bitcoin-aml
  tab: Cryptocurrency AML Detection
  url: https://github.com/mpaulinv/elliptic-bitcoin-aml
  description: >
    Built a robust analytics system to detect illicit Bitcoin transactions at scale, combining graph-based machine learning with advanced neural networks to tackle the challenge of financial crime in cryptocurrency. Successfully handled severely imbalanced data (rare illicit transactions), adversarial blockchain environments, and strict regulatory compliance requirements. Delivered a system that outperformed complex deep learning approaches through strategic feature engineering, demonstrating that domain expertise often trumps model complexity in financial applications.
  objective: >
    Develop a comprehensive anti-money laundering (AML) solution that addresses the unique challenges of cryptocurrency compliance: detecting rare illicit transactions in massive, noisy blockchain networks while meeting regulatory requirements for explainability and temporal validation. Create a system that supports real-world compliance workflows and can adapt to evolving criminal patterns in adversarial financial environments.
  overview: >
    Engineered a comprehensive AML detection pipeline using the Elliptic dataset, implementing advanced graph feature extraction that captures the complex relationships in blockchain transaction networks. Developed competing approaches: Random Forest with engineered features vs. Graph Attention Networks (GAT), discovering that sophisticated feature engineering often outperforms deep learning in financial domains. Designed temporal data splits that mirror real-world regulatory scenarios where models must predict future criminal activity based on historical patterns. Created rich visualizations revealing the distinct signatures of illicit transactions: high network density with low clustering coefficients, providing actionable insights for compliance teams.
  tech_stack: [Python, NetworkX, scikit-learn, PyTorch, matplotlib, pandas, seaborn]
  methods: |
    - Engineered 15+ sophisticated graph features (betweenness centrality, eigenvector centrality, clustering coefficients, ego network properties) to capture illicit transaction signatures in complex blockchain networks.
    - Built competing model architectures: hyperparameter-tuned Random Forest vs. Graph Attention Network (GAT), systematically evaluating traditional ML against deep learning approaches for financial crime detection.
    - Implemented regulatory-compliant temporal validation: training on historical data (timesteps 1-34), testing on future transactions to simulate real-world deployment where criminals adapt their strategies.
    - Critical data challenges: severe class imbalance (rare illicit transactions), high feature correlation, label noise, and data drift around regulatory changes at timestep 43.
    - Developed comprehensive analysis framework: correlation heatmaps identifying feature redundancy, temporal network visualizations showing criminal pattern evolution, and side-by-side prediction comparisons enabling model trust and debugging.
  results: >
    Discovered that Random Forest with engineered graph features significantly outperformed Graph Attention Networks on test data, revealing a key insight for financial ML: domain-specific feature engineering often beats deep learning complexity in adversarial environments. Identified distinct illicit transaction patterns: criminals create high-density networks with low clustering coefficients, enabling targeted detection strategies. Visualizations uncovered temporal patterns in criminal behavior and provided interpretable evidence for compliance reporting. The system achieved robust performance on severely imbalanced data while maintaining explainability required for regulatory environments.
  impact: >
    Delivered production-ready tools that solve real compliance challenges: handling adversarial data where criminals actively try to evade detection, working with severely imbalanced datasets where illicit transactions are rare, and meeting regulatory requirements for model explainability and temporal validation. Developed deep expertise in financial crime ML including data drift analysis, feature selection under multicollinearity, and building trust in AI systems for high-stakes regulatory decisions. Demonstrated that sophisticated feature engineering can outperform complex neural networks in specialized financial domains, providing a template for practical AML implementations.
  date: 2025-05
  images:
    - /assets/images/network_predictions.png
- repo: heart_disease
  tab: Heart Disease Prediction
  url: https://github.com/mpaulinv/heart_disease
  description: >
    Developed a complete end-to-end ML pipeline for predicting heart disease risk using the Cleveland dataset. Emphasized model interpretability, feature engineering, and actionable healthcare insights in the presence of real-world data challenges.
  objective: >
    Enable explainable, early prediction of heart disease to empower clinicians and patients with evidence-based risk assessments and feature insights.
  overview: >
    Explored and visualized the Cleveland Heart Disease dataset, engineered predictive features and interaction terms, and built interpretable models (logistic regression, Random Forest). Delivered reports on key risk factors and model performance.
  tech_stack: [Python, pandas, scikit-learn, matplotlib, seaborn]
  methods: |
    - Performed detailed EDA and feature engineering, including interaction terms and dummy variables.
    - Trained and tuned logistic regression and Random Forest models.
    - Evaluated with performance metrics: accuracy, precision, recall, F1, AUC.
    - Interpreted coefficients and feature importance for actionable insights.
  results: >
    Achieved robust predictive accuracy; identified and explained the main clinical risk factors for heart disease. Produced transparent reports for non-technical stakeholders.
  impact: >
    Developed skills in model interpretability and stakeholder communication.
  date: 2025-04
  images:
    - /assets/images/importance.png
    - /assets/images/roc.png
- repo: lichess_dashboard
  tab: Chess Performance Dashboard
  url: https://github.com/mpaulinv/lichess_dashboard
  description: >
    Created a full-featured Streamlit dashboard for real-time chess analytics, using Lichess data to help players understand and improve their performance. Overcame data normalization, API integration, and visualization challenges.
  objective: >
    Give chess players actionable insights into their strengths, weaknesses, and progress using intuitive, customizable analytics dashboards.
  overview: >
    Built a responsive dashboard with Streamlit and Plotly, integrating the Lichess API to fetch and process game data. Features include rating progression, win rate breakdown, opening repertoire analysis, and exportable reports—all with advanced filtering and interactive charts.
  tech_stack: [Python, Streamlit, pandas, Plotly, Lichess API]
  methods: |
    - Integrated with Lichess API for real-time game retrieval and user authentication.
    - Built interactive visualizations for ratings, openings, win rates, and more.
    - Implemented advanced filtering (date range, variant, game type) and export capabilities.
    - Optimized performance with caching and parallel processing.
  results: >
    Developed a workable website that can extract and process data in real-time and provide insights into a production environment.
  impact: >
    Developed skills in data processing and presentation.
  date: 2025-05
  images:
    - /assets/images/dashboard.png
- repo: roberta_qa
  tab: Question Answering with RoBERTa
  url: https://github.com/mpaulinv/roberta_qa
  description: >
    Investigated and improved RoBERTa’s performance on challenging "why" questions in QA tasks, using data augmentation and adversarial evaluation. Analyzed model limitations in causal reasoning and robustness.
  objective: >
    Advance machine reasoning in NLP by enabling robust, explainable question answering on causal ("why") questions, a key hurdle for trustworthy AI.
  overview: >
    Systematically analyzed RoBERTa’s failures on "why" questions from SQuAD and adversarial datasets. Applied TextAttack and CLARE for data augmentation, experimented with transfer learning, and visualized error patterns. Benchmarked with custom metrics and error taxonomies.
  tech_stack: [Python, PyTorch, HuggingFace Transformers, TextAttack, matplotlib]
  methods: |
    - Evaluated RoBERTa on standard and adversarial QA benchmarks.
    - Categorized errors and identified primary failure modes in causal reasoning.
    - Applied data augmentation (synonym replacement, context perturbation) and transfer learning with Quoref.
    - Visualized error types, performance gaps, and dataset-specific challenges.
  results: >
    Identified key sources of performance gaps and modestly improved adversarial robustness with fine-tuning and augmentation. Provided recommendations for future model and dataset design.
  impact: >
    Advanced understanding of NLP model limitations; contributed insights for building more trustworthy, explainable AI systems.
  date: 2024-11
  images:
    - /assets/images/results.png

